{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVaH6qoo_vtm"
      },
      "source": [
        "# Dataset Coding Challenge\n",
        "\n",
        "## Objective:\n",
        "Prepare a dataset for training an ML model on the airfRANS data.\n",
        "\n",
        "The airfRANS dataset is a collection of airfoils and their RANS simulation solution. The [documentation](https://airfrans.readthedocs.io/en/latest/notes/dataset.html) describes the dataset and the functionality in the Python library they've built in detail.\n",
        "\n",
        "Ask:\n",
        "* Create a dataset for training an ML model using the airfRANS dataset.\n",
        "  * The dataset should provide a sequence of points with their SDF (distance from the airfoil) value as the input `(x, y, sdf)` and the velocity `(x, y, v_x, v_y`) as the target. Package the data such that it can be quickly loaded for training a model.\n",
        "* Provide some dataset statistics to help users understand the data.\n",
        "* Document your design decisions.\n",
        "\n",
        "### Note:\n",
        "This is an intentionally open-ended challenge. The primary objective is to see how you write code. Think of this as an evaluation of your ability to write code for a production environment.\n",
        "\n",
        "## Time\n",
        "This challenge is designed to take ~2-3 hours. If it's taking much longer than that, feel free to stop and document what your next steps would have been.\n",
        "\n",
        "## Deliverables\n",
        "Your choice. You can send us a github repo, jupyter notebook, or just raw files. Do whatever you think will best demonstrate your SW engineering skills."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulA8ezF_-qEP"
      },
      "source": [
        "# Data Processing\n",
        "The below provides some sample code to help with basic dataset loading of the airfrans dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5LjkHnmO3afC",
        "outputId": "a5500379-1ef8-441b-cfd0-70f00bd76dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libgl1-mesa-glx is already the newest version (23.0.4-0ubuntu1~22.04.1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install airfrans --quiet\n",
        "!pip install pyvista --quiet\n",
        "!sudo apt install libgl1-mesa-glx xvfb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6h-7WQ903Ahu"
      },
      "outputs": [],
      "source": [
        "import airfrans as af\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from itertools import chain, islice\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Sigc43-13WRW"
      },
      "outputs": [],
      "source": [
        "# This has already been run\n",
        "# Download the dataset\n",
        "# NOTE: Dataset documentation can be found here: https://airfrans.readthedocs.io/en/latest/notes/dataset.html\n",
        "\n",
        "directory_name = Path('airfrans/')\n",
        "file_name = 'Dataset'\n",
        "if not directory_name.exists() or not any(directory_name.iterdir()):\n",
        "    af.dataset.download(root=str(directory_name), file_name=file_name, unzip=True, OpenFOAM=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liv0xrzF9G7n",
        "outputId": "2a99a520-2b31-4f0b-e27c-aa8190669869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset (task: reynolds, split: train): 100%|██████████| 504/504 [04:11<00:00,  2.00it/s]\n"
          ]
        }
      ],
      "source": [
        "# Note: we use the `reynolds` task here to prevent a memory error with Colab. Feel free to use `full` if doing this offline.\n",
        "dataset_list, dataset_name = af.dataset.load(root=str(directory_name/file_name), task = 'reynolds', train = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtSCCrt7uVoB",
        "outputId": "841d6267-a4f3-4fe2-d7eb-3fc6755c2d98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ♥ Dataset Overview ♥ ---\n",
            "\n",
            "Dataset_name: <class 'list'> containing elements of type <class 'str'>\n",
            "\n",
            "\tExample element: airFoil2D_SST_58.831_-3.563_2.815_4.916_10.078\n",
            "\tLength: 504 elements\n",
            "\t- NACA 4-digit count: 239\n",
            "\t- NACA 5-digit count: 265\n",
            "\tInlet velocity range: 46.84 to 77.95\n",
            "\tAngle of attack range: -4.93 to 14.79\n",
            "\n",
            "Dataset_list: <class 'list'> containing elements of type <class 'numpy.ndarray'>\n",
            "\n",
            "\tLength: 504 elements\n",
            "\tShape of each element: (N, 12)\n",
            "\t-  N: number of points in simulation\n",
            "\t- 12: number of features\n",
            "\tNumber of points in first simulation as reference: 170,180\n",
            "\t- Note: number of points in simulations vary a bit\n",
            "\n",
            "\tDescription of 12 features, in order: \n",
            "\tPosition x\tPosition y\tInlet velocity\tInlet velocity\t\n",
            "\tDist to airfoil\tNormals a\tNormals b\tVelocity x\t\n",
            "\tVelocity y\tPressure/mass\tKin. viscosity\tBool*\n",
            "\t\n",
            "\t*Evals to true if point lies on the airfoil\n"
          ]
        }
      ],
      "source": [
        "# Some set basics!\n",
        "\n",
        "T = 298.15 # As recommended in original documentation\n",
        "inlet_velocity = []\n",
        "angle_attack = []\n",
        "digits4 = []\n",
        "digits5 = []\n",
        "\n",
        "for item in dataset_name:\n",
        "    params = item.split('_')\n",
        "    inlet_velocity.append(float(params[2]))\n",
        "    angle_attack.append(float(params[3]))\n",
        "\n",
        "    if len(params) == 7:\n",
        "        digits4.append(list(map(float, params[-3:])))\n",
        "    else:\n",
        "        digits5.append(list(map(float, params[-4:])))\n",
        "\n",
        "print(\"\\n--- ♥ Dataset Overview ♥ ---\")\n",
        "print(f\"\\nDataset_name: {type(dataset_name)} containing elements of type {type(dataset_name[0])}\")\n",
        "print(f\"\\n\\tExample element: {dataset_name[0]}\")\n",
        "print(f\"\\tLength: {len(dataset_name):,} elements\")\n",
        "print(f\"\\t- NACA 4-digit count: {len(digits4):,}\")\n",
        "print(f\"\\t- NACA 5-digit count: {len(digits5):,}\")\n",
        "print(f\"\\tInlet velocity range: {min(inlet_velocity):.2f} to {max(inlet_velocity):.2f}\")\n",
        "print(f\"\\tAngle of attack range: {min(angle_attack):.2f} to {max(angle_attack):.2f}\")\n",
        "\n",
        "print(f\"\\nDataset_list: {type(dataset_list)} containing elements of type {type(dataset_list[0])}\")\n",
        "print(f\"\\n\\tLength: {len(dataset_list):,} elements\")\n",
        "print(f\"\\tShape of each element: (N, 12)\")\n",
        "print(f\"\\t-  N: number of points in simulation\")\n",
        "print(f\"\\t- 12: number of features\")\n",
        "print(f\"\\tNumber of points in first simulation as reference: {len(dataset_list[0][:]):,}\")\n",
        "print(f\"\\t- Note: number of points in simulations vary a bit\")\n",
        "\n",
        "features = [\n",
        "    [\"\\tPosition x\", \"Position y\", \"Inlet velocity\", \"Inlet velocity\"],\n",
        "    [\"\\tDist to airfoil\", \"Normals a\", \"Normals b\", \"Velocity x\"],\n",
        "    [\"\\tVelocity y\", \"Pressure/mass\", \"Kin. viscosity\", \"Bool*\"]\n",
        "]\n",
        "\n",
        "print(\"\\n\\tDescription of 12 features, in order: \")\n",
        "print('\\t\\n'.join(['\\t'.join([str(cell) for cell in row]) for row in features]))\n",
        "print(\"\\t\\n\\t*Evals to true if point lies on the airfoil\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WzgzatWnbJju"
      },
      "outputs": [],
      "source": [
        "# Input:   dataset_list\n",
        "# Output:  tensor(input: x, y, sdf), tensor(target: x, y, v_x, v_y)\n",
        "#\n",
        "# Challenges:\n",
        "#   Memory Usage.\n",
        "#      - `af.dataset.load` pulls all data into RAM, little left to play with.\n",
        "#   Indexing.\n",
        "#      - Pulling datapoints from multiple simluations means we want an indexable dataset, but simulations have varying vertical dimensions\n",
        "#      - We coud use something like np.vstack, but this would create copies of dataset. Back to memory problem.\n",
        "#\n",
        "# Solution:\n",
        "#   Avoid making any copies and directly reference data in RAM.\n",
        "#      - Pros: Keeps RAM usage low! No need to spend money.\n",
        "#      - Next steps: Do sanity check with teammates who understand physics part of it. Test the current code and explore how\n",
        "#        Geometric Deep Learning libraries could help (mentioned in airfRANS documentation)\n",
        "\n",
        "class AirfoilDataset(Dataset):\n",
        "    def __init__(self, dataset_list):\n",
        "        self.dataset_list = dataset_list\n",
        "\n",
        "        # find total number of datapoints\n",
        "        self.dataset_length = sum(sim.shape[0] for sim in dataset_list)\n",
        "\n",
        "        # create iterator\n",
        "        self.all_rows = chain.from_iterable(dataset_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        elem = next(islice(self.all_rows, idx, idx+1))\n",
        "\n",
        "        # pull features we need\n",
        "        x = elem[0]\n",
        "        y = elem[1]\n",
        "        sdf = elem[4]\n",
        "        v_x = elem[7]\n",
        "        v_y = elem[8]\n",
        "\n",
        "        # put everything in tensor\n",
        "        input = torch.cat([torch.tensor((x, y, sdf), dtype = torch.float)])\n",
        "        target = torch.cat([torch.tensor((x, y, v_x, v_y), dtype = torch.float)])\n",
        "        return input, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT_uLpAElfUV",
        "outputId": "c16912f0-ec16-47eb-acf9-ca0f623432d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([ 4.2169, -0.1999,  3.2231]), tensor([ 4.2169, -0.1999, 54.5453, -3.3534]))\n"
          ]
        }
      ],
      "source": [
        "# Example output\n",
        "\n",
        "dataset = AirfoilDataset(dataset_list)\n",
        "print(dataset.__getitem__(0))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}